{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST from scratch with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load changed modules automatically\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load numpy\n",
    "import numpy as np\n",
    "\n",
    "# load dataloaders and required layers\n",
    "from mnist import dataloader\n",
    "from mnist.layers import Softmax, Linear, Dropout, ReLU\n",
    "from mnist.losses import CrossEntropy\n",
    "\n",
    "# load pyplot for displaying images\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# show images inline on notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# debugging\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = dataloader.DataLoader()\n",
    "((x_train, y_train), (x_valid, y_valid), (x_test, (y_test))) = dl.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 784), (50000,), (10000, 784), (10000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_valid, y_valid) = dl.normalize(((x_train, y_train), (x_valid, y_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def show(img):\n",
    "    plt.imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "valid_images = np.reshape(x_valid, (-1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "show(valid_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(arr1, arr2):\n",
    "    random_idxs = np.arange(len(arr1))\n",
    "    np.random.shuffle(random_idxs)\n",
    "    return arr1[random_idxs], arr2[random_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# always reproduce the same weights\n",
    "np.random.seed(1)\n",
    "\n",
    "class Net(object):\n",
    "    def __init__(self):\n",
    "        self.train = True\n",
    "        self.input_layer = Linear(28*28, 10) # linear layer with bias\n",
    "        self.softmax = Softmax()\n",
    "        self.dropout = Dropout(0.1)\n",
    "        self.cross_entropy = CrossEntropy()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.train:\n",
    "            x = self.dropout.forward(x)\n",
    "\n",
    "        x = self.input_layer.forward(x)\n",
    "        x = self.softmax.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def backward(self, targets):\n",
    "        grad_loss = net.softmax.backward(targets)\n",
    "        _, grad_input_layer, grad_bias = net.input_layer.backward(grad_loss)\n",
    "        return grad_input_layer, grad_bias\n",
    "    \n",
    "    def loss(self, y_pred, y):\n",
    "        return self.cross_entropy.loss(y_pred, y)\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.3000072308119785 0.39073117677176367 0.9125 0.87890625\n",
      "1 0.2876592412435876 0.26661347190416196 0.925 0.921875\n",
      "2 0.2673505985865531 0.2221052878748185 0.9125 0.9296875\n",
      "3 0.24457945156017638 0.26941002948725695 0.925 0.9140625\n",
      "4 0.21023881608801612 0.24110944605246998 0.9125 0.921875\n",
      "5 0.2604654879336149 0.202457411572795 0.925 0.9375\n",
      "6 0.21781252505162216 0.26353541941770986 0.925 0.921875\n",
      "7 0.18740159405502868 0.25993454975499963 0.925 0.92578125\n",
      "8 0.2367375968294728 0.28525791613123685 0.9375 0.92578125\n",
      "9 0.20236202025208733 0.25875342289821923 0.925 0.9453125\n"
     ]
    }
   ],
   "source": [
    "debug = False\n",
    "\n",
    "if debug:\n",
    "    n_epochs = 1\n",
    "    batch_size = 3\n",
    "else:\n",
    "    n_epochs = 10\n",
    "    batch_size = 256\n",
    "    \n",
    "learning_rate = 1e-1\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    for i in range(0, len(x_train), batch_size):\n",
    "\n",
    "        inputs = x_train[i:i+batch_size]\n",
    "        targets = y_train[i:i+batch_size]\n",
    "        \n",
    "        inputs, targets = shuffle(inputs, targets)\n",
    "\n",
    "        if debug:\n",
    "            print(\"inputs.shape\", inputs.shape)\n",
    "            print(\"targets.shape\", targets.shape)\n",
    "\n",
    "        # forward propagation\n",
    "        y_pred = net.forward(inputs)\n",
    "        predictions = y_pred.copy()\n",
    "\n",
    "        if debug:\n",
    "            print(\"y_pred.shape:\", y_pred.shape)\n",
    "            print(\"predictions.shape\", predictions.shape)\n",
    "            \n",
    "        # calculate cross-entropy loss\n",
    "        loss = net.loss(predictions, targets)\n",
    "        \n",
    "        if debug:\n",
    "            print(epoch, loss)\n",
    "        \n",
    "        # backpropagation\n",
    "        grad_input_layer, grad_bias = net.backward(targets)\n",
    "        \n",
    "        if debug:\n",
    "            print(\"grad_input_layer.shape\", grad_input_layer.shape)\n",
    "            print(\"net.input_layer.weights.shape\", net.input_layer.weights.shape)\n",
    "            print(\"net.input_layer.bias.shape\", net.input_layer.bias.shape)\n",
    "        \n",
    "        net.input_layer.weights -= learning_rate * grad_input_layer\n",
    "        net.input_layer.bias -= learning_rate * grad_bias\n",
    "        \n",
    "        if debug:\n",
    "            break\n",
    "        \n",
    "    # calculate validation loss for some random indices\n",
    "    net.train = False\n",
    "    random_idxs = np.random.randint(0, len(x_valid), batch_size)\n",
    "    y_valid_pred = net.forward(x_valid[random_idxs])\n",
    "    loss_valid = net.loss(y_valid_pred, y_valid[random_idxs])\n",
    "    net.train = True\n",
    "    \n",
    "    #calculate accuracy and validation accuracy\n",
    "    accuracy = np.mean(y_pred.argmax(axis=1) == targets)\n",
    "    valid_accuracy = np.mean(y_valid_pred.argmax(axis=1) == y_valid[random_idxs])\n",
    "    \n",
    "    print(epoch, loss, loss_valid, accuracy, valid_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 8, 0, 4, 2, 9, 8, 7, 4, 4]), array([0, 8, 0, 4, 2, 9, 0, 7, 4, 4]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get some random examples from validation data,\n",
    "# compare predictions with actual values\n",
    "valid_preds = net.forward(x_valid)\n",
    "random_idxs = np.random.randint(0, len(x_valid), 10)\n",
    "np.argmax(valid_preds, axis=1)[random_idxs], y_valid[random_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: 1 correct: 1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'show' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-97a5675a4f7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"prediction:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"correct:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'show' is not defined"
     ]
    }
   ],
   "source": [
    "# display a random image from validation data with\n",
    "# prediction and correct value\n",
    "valid_images = np.reshape(x_valid, (-1,28,28))\n",
    "valid_preds = net.forward(x_valid)\n",
    "random_idx = np.random.randint(0, len(x_valid))\n",
    "prediction = np.argmax(valid_preds, axis=1)[random_idx]\n",
    "correct = y_valid[random_idx]\n",
    "print(\"prediction:\", prediction, \"correct:\", correct)\n",
    "show(valid_images[random_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
