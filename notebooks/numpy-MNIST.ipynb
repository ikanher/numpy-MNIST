{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST from scratch with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load changed modules automatically\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load numpy\n",
    "import numpy as np\n",
    "\n",
    "# load dataloaders and required layers\n",
    "from mnist import dataloader\n",
    "from mnist.layers import Softmax, Linear, Dropout, ReLU\n",
    "from mnist.losses import CrossEntropy\n",
    "\n",
    "# load pyplot for displaying images\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# show images inline on notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# debugging\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = dataloader.DataLoader()\n",
    "((x_train, y_train), (x_valid, y_valid), (x_test, (y_test))) = dl.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 784), (50000,), (10000, 784), (10000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_valid, y_valid) = dl.normalize(((x_train, y_train), (x_valid, y_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def show(img):\n",
    "    plt.imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "valid_images = np.reshape(x_valid, (-1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "show(valid_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(arr1, arr2):\n",
    "    random_idxs = np.arange(len(arr1))\n",
    "    np.random.shuffle(random_idxs)\n",
    "    return arr1[random_idxs], arr2[random_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# always reproduce the same weights\n",
    "np.random.seed(1)\n",
    "\n",
    "class Net(object):\n",
    "    def __init__(self):\n",
    "        self.train = True\n",
    "        self.input_layer = Linear(28*28, 10) # linear layer with bias\n",
    "        self.softmax = Softmax()\n",
    "        self.dropout = Dropout(0.1)\n",
    "        self.cross_entropy = CrossEntropy()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.train:\n",
    "            x = self.dropout.forward(x)\n",
    "\n",
    "        x = self.input_layer.forward(x)\n",
    "        x = self.softmax.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def backward(self, targets):\n",
    "        grad_loss = net.softmax.backward(targets)\n",
    "        _, grad_input_layer, grad_bias = net.input_layer.backward(grad_loss)\n",
    "        return grad_input_layer, grad_bias\n",
    "    \n",
    "    def loss(self, y_pred, y):\n",
    "        return self.cross_entropy.loss(y_pred, y)\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.42844615847357737 0.35011324464343074 0.8988095238095238 0.896484375\n"
     ]
    }
   ],
   "source": [
    "debug = False\n",
    "\n",
    "if debug:\n",
    "    n_epochs = 1\n",
    "    batch_size = 3\n",
    "else:\n",
    "    n_epochs = 10\n",
    "    batch_size = 512\n",
    "    \n",
    "learning_rate = 1e-1\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    for i in range(0, len(x_train), batch_size):\n",
    "\n",
    "        inputs = x_train[i:i+batch_size]\n",
    "        targets = y_train[i:i+batch_size]\n",
    "        \n",
    "        inputs, targets = shuffle(inputs, targets)\n",
    "\n",
    "        if debug:\n",
    "            print(\"inputs.shape\", inputs.shape)\n",
    "            print(\"targets.shape\", targets.shape)\n",
    "\n",
    "        # forward propagation\n",
    "        y_pred = net.forward(inputs)\n",
    "        predictions = y_pred.copy()\n",
    "\n",
    "        if debug:\n",
    "            print(\"y_pred.shape:\", y_pred.shape)\n",
    "            print(\"predictions.shape\", predictions.shape)\n",
    "            \n",
    "        # calculate cross-entropy loss\n",
    "        loss = net.loss(predictions, targets)\n",
    "        \n",
    "        if debug:\n",
    "            print(epoch, loss)\n",
    "        \n",
    "        # backpropagation\n",
    "        grad_input_layer, grad_bias = net.backward(targets)\n",
    "        \n",
    "        if debug:\n",
    "            print(\"grad_input_layer.shape\", grad_input_layer.shape)\n",
    "            print(\"net.input_layer.weights.shape\", net.input_layer.weights.shape)\n",
    "            print(\"net.input_layer.bias.shape\", net.input_layer.bias.shape)\n",
    "        \n",
    "        net.input_layer.weights -= learning_rate * grad_input_layer\n",
    "        net.input_layer.bias -= learning_rate * grad_bias\n",
    "        \n",
    "        if debug:\n",
    "            break\n",
    "        \n",
    "    # calculate validation loss for some random indices\n",
    "    net.train = False\n",
    "    random_idxs = np.random.randint(0, len(x_valid), batch_size)\n",
    "    y_valid_pred = net.forward(x_valid[random_idxs])\n",
    "    loss_valid = net.loss(y_valid_pred, y_valid[random_idxs])\n",
    "    net.train = True\n",
    "    \n",
    "    #calculate accuracy and validation accuracy\n",
    "    accuracy = np.mean(y_pred.argmax(axis=1) == targets)\n",
    "    valid_accuracy = np.mean(y_valid_pred.argmax(axis=1) == y_valid[random_idxs])\n",
    "    \n",
    "    print(epoch, loss, loss_valid, accuracy, valid_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some random examples from validation data,\n",
    "# compare predictions with actual values\n",
    "valid_preds = net.forward(x_valid)\n",
    "random_idxs = np.random.randint(0, len(x_valid), 10)\n",
    "np.argmax(valid_preds, axis=1)[random_idxs], y_valid[random_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display a random image from validation data with\n",
    "# prediction and correct value\n",
    "valid_images = np.reshape(x_valid, (-1,28,28))\n",
    "valid_preds = net.forward(x_valid)\n",
    "random_idx = np.random.randint(0, len(x_valid))\n",
    "prediction = np.argmax(valid_preds, axis=1)[random_idx]\n",
    "correct = y_valid[random_idx]\n",
    "print(\"prediction:\", prediction, \"correct:\", correct)\n",
    "show(valid_images[random_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
