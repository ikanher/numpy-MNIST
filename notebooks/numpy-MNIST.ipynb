{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST from scratch with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load changed modules automatically\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load numpy\n",
    "import numpy as np\n",
    "\n",
    "# load dataloaders and required layers\n",
    "from mnist import dataloader\n",
    "from mnist.layers import Softmax, Linear, Dropout, ReLU\n",
    "from mnist.losses import CrossEntropy\n",
    "\n",
    "# load pyplot for displaying images\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# show images inline on notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# debugging\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = dataloader.DataLoader()\n",
    "((x_train, y_train), (x_valid, y_valid), (x_test, (y_test))) = dl.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 784), (50000,), (10000, 784), (10000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_valid, y_valid) = dl.normalize(((x_train, y_train), (x_valid, y_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def show(img):\n",
    "    plt.imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "valid_images = np.reshape(x_valid, (-1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "show(valid_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(arr1, arr2):\n",
    "    random_idxs = np.arange(len(arr1))\n",
    "    np.random.shuffle(random_idxs)\n",
    "    return x_train[random_idxs], y_train[random_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# always reproduce the same weights\n",
    "np.random.seed(1)\n",
    "\n",
    "class Net(object):\n",
    "    def __init__(self):\n",
    "        self.train = True\n",
    "        self.input_layer = Linear(28*28, 10) # linear layer with bias\n",
    "        self.softmax = Softmax()\n",
    "        self.dropout = Dropout(0.8)\n",
    "        self.cross_entropy = CrossEntropy()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.train:\n",
    "            x = self.dropout.forward(x)\n",
    "\n",
    "        x = self.input_layer.forward(x)\n",
    "        x = self.softmax.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def backward(self, predictions, y):\n",
    "        grad_loss = net.softmax.backward(predictions, y)\n",
    "        _, grad_input_layer, grad_bias = net.input_layer.backward(grad_loss)\n",
    "        return grad_input_layer, grad_bias\n",
    "    \n",
    "    def loss(self, y_pred, y):\n",
    "        return self.cross_entropy.loss(y_pred, y)\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.24448745589456217 0.7250704680308275 0.9 0.78515625\n",
      "1 0.2678010473263808 0.8249318496133424 0.9 0.796875\n",
      "2 0.29367190753760114 0.6399052549460673 0.9125 0.828125\n",
      "3 0.2031626469135543 0.960821130991464 0.925 0.76953125\n",
      "4 0.3175400918884881 0.7460730697805749 0.8875 0.81640625\n",
      "5 0.19044868753028937 0.9405618821977141 0.9125 0.77734375\n",
      "6 0.1851131097974233 0.796294352013525 0.9375 0.83203125\n",
      "7 0.1469066520257561 0.9537574536330944 0.95 0.796875\n",
      "8 0.18294786687004044 0.8327363894245562 0.95 0.84375\n",
      "9 0.11371112750016225 0.9466581825744765 0.975 0.80859375\n",
      "10 0.21408967038593038 0.8659946562883748 0.925 0.80859375\n",
      "11 0.1988773233856596 0.6723050405379363 0.925 0.8515625\n",
      "12 0.17156010032208044 1.0133803311847793 0.9375 0.78125\n",
      "13 0.21505484854899698 0.6588301368824367 0.9125 0.8125\n",
      "14 0.30363388029933225 0.9129873371935626 0.9125 0.83203125\n",
      "15 0.2648701102646583 0.9973765702531434 0.925 0.828125\n",
      "16 0.2115346982144235 1.1574537113298349 0.925 0.79296875\n",
      "17 0.25350815193781406 1.2490367192913021 0.925 0.7734375\n",
      "18 0.1129749006497686 0.8651328691465909 0.975 0.859375\n",
      "19 0.2211989089294383 1.2396732116808502 0.9125 0.78515625\n"
     ]
    }
   ],
   "source": [
    "debug = False\n",
    "\n",
    "if debug:\n",
    "    n_epochs = 1\n",
    "    batch_size = 3\n",
    "else:\n",
    "    n_epochs = 20\n",
    "    batch_size = 256\n",
    "    \n",
    "learning_rate = 1e-1\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    for i in range(0, len(x_train), batch_size):\n",
    "\n",
    "        inputs = x_train[i:i+batch_size]\n",
    "        targets = y_train[i:i+batch_size]\n",
    "        \n",
    "        inputs, targets = shuffle(inputs, targets)\n",
    "\n",
    "        if debug:\n",
    "            print(\"inputs.shape\", inputs.shape)\n",
    "            print(\"targets.shape\", targets.shape)\n",
    "\n",
    "        # forward propagation\n",
    "        y_pred = net.forward(inputs)\n",
    "        predictions = y_pred.copy()\n",
    "\n",
    "        if debug:\n",
    "            print(\"y_pred.shape:\", y_pred.shape)\n",
    "            print(\"predictions.shape\", predictions.shape)\n",
    "            \n",
    "        # calculate cross-entropy loss\n",
    "        loss = net.loss(predictions, targets)\n",
    "        \n",
    "        if debug:\n",
    "            print(epoch, loss)\n",
    "        \n",
    "        # backpropagation        \n",
    "        grad_input_layer, grad_bias = net.backward(predictions, targets)\n",
    "        \n",
    "        if debug:\n",
    "            print(\"grad_input_layer.shape\", grad_input_layer.shape)\n",
    "            print(\"net.input_layer.weights.shape\", net.input_layer.weights.shape)\n",
    "            print(\"net.input_layer.bias.shape\", net.input_layer.bias.shape)\n",
    "        \n",
    "        net.input_layer.weights -= learning_rate * grad_input_layer\n",
    "        net.input_layer.bias -= learning_rate * grad_bias\n",
    "        \n",
    "        if debug:\n",
    "            break\n",
    "        \n",
    "    # calculate validation loss for some random indices\n",
    "    net.train = False\n",
    "    random_idxs = np.random.randint(0, len(x_valid), batch_size)\n",
    "    y_valid_pred = net.forward(x_valid[random_idxs])\n",
    "    loss_valid = net.loss(y_valid_pred, y_valid[random_idxs])\n",
    "    net.train = True\n",
    "    \n",
    "    #calculate accuracy and validation accuracy\n",
    "    accuracy = np.mean(y_pred.argmax(axis=1) == targets)\n",
    "    valid_accuracy = np.mean(y_valid_pred.argmax(axis=1) == y_valid[random_idxs])\n",
    "    \n",
    "    print(epoch, loss, loss_valid, accuracy, valid_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([7, 0, 4, 8, 4, 9, 8, 6, 6, 4]), array([7, 0, 4, 8, 4, 8, 8, 6, 2, 4]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get some random examples from validation data,\n",
    "# compare predictions with actual values\n",
    "valid_preds = net.forward(x_valid)\n",
    "random_idxs = np.random.randint(0, len(x_valid), 10)\n",
    "np.argmax(valid_preds, axis=1)[random_idxs], y_valid[random_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: 3 correct: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display a random image from validation data with\n",
    "# prediction and correct value\n",
    "valid_images = np.reshape(x_valid, (-1,28,28))\n",
    "valid_preds = net.forward(x_valid)\n",
    "random_idx = np.random.randint(0, len(x_valid))\n",
    "prediction = np.argmax(valid_preds, axis=1)[random_idx]\n",
    "correct = y_valid[random_idx]\n",
    "print(\"prediction:\", prediction, \"correct:\", correct)\n",
    "show(valid_images[random_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
