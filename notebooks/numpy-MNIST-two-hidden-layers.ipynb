{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST from scratch with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load changed modules automatically\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load numpy\n",
    "import numpy as np\n",
    "\n",
    "# load dataloaders and required layers\n",
    "from mnist import dataloader\n",
    "from mnist.layers import Softmax, Linear, Dropout, ReLU\n",
    "from mnist.losses import CrossEntropy\n",
    "\n",
    "# load pyplot for displaying images\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# show images inline on notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# debugging\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = dataloader.DataLoader()\n",
    "((x_train, y_train), (x_valid, y_valid), (x_test, (y_test))) = dl.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 784), (50000,), (10000, 784), (10000,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_valid, y_valid) = dl.normalize(((x_train, y_train), (x_valid, y_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def show(img):\n",
    "    plt.imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "valid_images = np.reshape(x_valid, (-1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "show(valid_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(arr1, arr2):\n",
    "    random_idxs = np.arange(len(arr1))\n",
    "    np.random.shuffle(random_idxs)\n",
    "    return arr1[random_idxs], arr2[random_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# always reproduce the same weights\n",
    "#np.random.seed(1)\n",
    "\n",
    "class Net(object):\n",
    "        \n",
    "    def __init__(self, n_input=28*28, n_hidden1=256, n_hidden2=256, n_output=10):\n",
    "        self.train = True\n",
    "        \n",
    "        self.input_dropout = Dropout(0.01)\n",
    "        self.input_layer = Linear(n_input, n_hidden1)\n",
    "        \n",
    "        self.relu1 = ReLU()\n",
    "        self.dropout1 = Dropout(0.5)\n",
    "        self.hidden1 = Linear(n_hidden1, n_hidden2)\n",
    "\n",
    "        self.relu2 = ReLU()\n",
    "        self.dropout2 = Dropout(0.01)\n",
    "        self.hidden2 = Linear(n_hidden2, n_output)\n",
    "\n",
    "        self.softmax = Softmax()\n",
    "        self.loss_func = CrossEntropy()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.train:\n",
    "            x = self.input_dropout.forward(x)\n",
    "\n",
    "        x = self.input_layer.forward(x)\n",
    "\n",
    "        if self.train:\n",
    "            x = self.dropout1.forward(x)\n",
    "    \n",
    "        x = self.relu1.forward(x)\n",
    "        x = self.hidden1.forward(x)\n",
    "\n",
    "        if self.train:\n",
    "            x = self.dropout2.forward(x)\n",
    "\n",
    "        x = self.relu2.forward(x)\n",
    "        x = self.hidden2.forward(x)\n",
    "        \n",
    "        x = self.softmax.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def backward(self, targets):\n",
    "        grads = {}\n",
    "        \n",
    "        grad_loss = net.softmax.backward(targets)\n",
    "\n",
    "        grad_hidden2_inputs, grad_hidden2_weights, grad_hidden2_bias = net.hidden2.backward(grad_loss)\n",
    "        grads['w3'] = grad_hidden2_weights\n",
    "        grads['b3'] = grad_hidden2_bias\n",
    "        \n",
    "        grad_relu = net.relu2.backward(grad_hidden2_inputs)\n",
    "\n",
    "        grad_hidden1_inputs, grad_hidden1_weights, grad_hidden1_bias = net.hidden1.backward(grad_relu)\n",
    "        grads['w2'] = grad_hidden1_weights\n",
    "        grads['b2'] = grad_hidden1_bias\n",
    "\n",
    "        grad_relu = net.relu1.backward(grad_hidden1_inputs)\n",
    "\n",
    "        grad_inputs, grad_input_weights, grad_input_bias = net.input_layer.backward(grad_relu)\n",
    "        grads['w1'] = grad_input_weights\n",
    "        grads['b1'] = grad_input_bias\n",
    "        \n",
    "        return grads\n",
    "    \n",
    "    def loss(self, y_pred, y):\n",
    "        return self.loss_func.loss(y_pred, y)\n",
    "\n",
    "net = Net(n_input=28*28, n_hidden1=256, n_hidden2=64, n_output=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.204526887092844 2.1849000822959828 0.225 0.2088\n",
      "1 0.5475592948171671 0.5627306641494987 0.8375 0.8325\n",
      "2 0.38459536850989623 0.35825926267685443 0.925 0.8945\n",
      "3 0.2754236548876779 0.25389087217608863 0.9375 0.9242\n",
      "4 0.24122200546327494 0.1966455054814806 0.9375 0.9421\n",
      "5 0.18474746947487813 0.17014792473003695 0.9375 0.9497\n",
      "6 0.13826313171550206 0.14281611675777536 0.9625 0.9571\n",
      "7 0.1418354444946957 0.12859858193897034 0.95 0.9619\n",
      "8 0.10089261807711436 0.1165010883791176 0.9875 0.9664\n",
      "9 0.12190666866166229 0.11170201921836631 0.95 0.9671\n",
      "10 0.0817662162028858 0.10258808439319816 0.9875 0.9698\n",
      "11 0.07020409116760706 0.09640664337103134 0.9875 0.9717\n",
      "12 0.05592583702554177 0.09566927165836384 0.9875 0.972\n",
      "13 0.07851278216779871 0.0887908847641861 0.9625 0.9735\n",
      "14 0.04234429972817784 0.08674091976798616 1.0 0.9741\n",
      "15 0.05140836187188584 0.08415198910921887 0.9875 0.9755\n",
      "16 0.044057615461404 0.08504818549454218 1.0 0.9746\n",
      "17 0.07809515121492513 0.08113659770213541 0.975 0.9758\n",
      "18 0.047339812148927934 0.07897154363245606 0.9875 0.9765\n",
      "19 0.03988158624495996 0.07742325758905565 1.0 0.977\n"
     ]
    }
   ],
   "source": [
    "debug = False\n",
    "\n",
    "if debug:\n",
    "    n_epochs = 1\n",
    "    batch_size = 3\n",
    "else:\n",
    "    n_epochs = 20\n",
    "    batch_size = 256\n",
    "    \n",
    "learning_rate = 1e-1\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    for i in range(0, len(x_train), batch_size):\n",
    "\n",
    "        inputs = x_train[i:i+batch_size]\n",
    "        targets = y_train[i:i+batch_size]\n",
    "        \n",
    "        inputs, targets = shuffle(inputs, targets)\n",
    "\n",
    "        if debug:\n",
    "            print(\"inputs.shape\", inputs.shape)\n",
    "            print(\"targets.shape\", targets.shape)\n",
    "\n",
    "        # forward propagation\n",
    "        y_pred = net.forward(inputs)\n",
    "        predictions = y_pred.copy()\n",
    "\n",
    "        if debug:\n",
    "            print(\"y_pred.shape:\", y_pred.shape)\n",
    "            print(\"predictions.shape\", predictions.shape)\n",
    "            \n",
    "        # calculate cross-entropy loss\n",
    "        loss = net.loss(predictions, targets)\n",
    "        \n",
    "        if debug:\n",
    "            print(epoch, loss)\n",
    "        \n",
    "        # backpropagation\n",
    "        grads = net.backward(targets)\n",
    "        \n",
    "        if debug:\n",
    "            print(\"w1.shape\", grads['w1'].shape)\n",
    "            print(\"b1.shape\", grads['b1'].shape)\n",
    "            print(\"w2.shape\", grads['w2'].shape)\n",
    "            print(\"b2.shape\", grads['b2'].shape)\n",
    "            \n",
    "        net.input_layer.weights -= learning_rate * grads['w1']\n",
    "        net.input_layer.bias -= learning_rate * grads['b1']\n",
    "        \n",
    "        net.hidden1.weights -= learning_rate * grads['w2']\n",
    "        net.hidden1.bias -= learning_rate * grads['b2']\n",
    "\n",
    "        net.hidden2.weights -= learning_rate * grads['w3']\n",
    "        net.hidden2.bias -= learning_rate * grads['b3']\n",
    "        \n",
    "        if debug:\n",
    "            break\n",
    "        \n",
    "    # calculate validation loss for some random indices\n",
    "#     net.train = False\n",
    "#     random_idxs = np.random.randint(0, len(x_valid), batch_size)\n",
    "#     y_valid_pred = net.forward(x_valid[random_idxs])\n",
    "#     loss_valid = net.loss(y_valid_pred, y_valid[random_idxs])\n",
    "#     net.train = True\n",
    "\n",
    "\n",
    "    net.train = False\n",
    "    y_valid_pred = net.forward(x_valid)\n",
    "    loss_valid = net.loss(y_valid_pred, y_valid)\n",
    "    net.train = True\n",
    "\n",
    "    #calculate accuracy and validation accuracy\n",
    "    accuracy = np.mean(y_pred.argmax(axis=1) == targets)\n",
    "    valid_accuracy = np.mean(y_valid_pred.argmax(axis=1) == y_valid)\n",
    "    \n",
    "    print(epoch, loss, loss_valid, accuracy, valid_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5, 1, 5, 0, 2, 3, 3, 7, 8, 7]), array([8, 1, 5, 0, 7, 3, 3, 7, 8, 7]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get some random examples from validation data,\n",
    "# compare predictions with actual values\n",
    "valid_preds = net.forward(x_valid)\n",
    "random_idxs = np.random.randint(0, len(x_valid), 10)\n",
    "np.argmax(valid_preds, axis=1)[random_idxs], y_valid[random_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: 5 correct: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display a random image from validation data with\n",
    "# prediction and correct value\n",
    "valid_images = np.reshape(x_valid, (-1,28,28))\n",
    "valid_preds = net.forward(x_valid)\n",
    "random_idx = np.random.randint(0, len(x_valid))\n",
    "prediction = np.argmax(valid_preds, axis=1)[random_idx]\n",
    "correct = y_valid[random_idx]\n",
    "print(\"prediction:\", prediction, \"correct:\", correct)\n",
    "show(valid_images[random_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9665"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# whole validation set accuracy\n",
    "valid_preds = net.forward(x_valid)\n",
    "valid_accuracy = np.mean(valid_preds.argmax(axis=1) == y_valid)\n",
    "valid_accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
