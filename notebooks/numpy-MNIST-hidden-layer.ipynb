{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST from scratch with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load changed modules automatically\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load numpy\n",
    "import numpy as np\n",
    "\n",
    "# load dataloaders and required layers\n",
    "from mnist import dataloader\n",
    "from mnist.layers import Softmax, Linear, Dropout, ReLU\n",
    "from mnist.losses import CrossEntropy\n",
    "\n",
    "# load pyplot for displaying images\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# show images inline on notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# debugging\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = dataloader.DataLoader()\n",
    "((x_train, y_train), (x_valid, y_valid), (x_test, (y_test))) = dl.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 784), (50000,), (10000, 784), (10000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_valid, y_valid) = dl.normalize(((x_train, y_train), (x_valid, y_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def show(img):\n",
    "    plt.imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "valid_images = np.reshape(x_valid, (-1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "show(valid_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(arr1, arr2):\n",
    "    random_idxs = np.arange(len(arr1))\n",
    "    np.random.shuffle(random_idxs)\n",
    "    return arr1[random_idxs], arr2[random_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# always reproduce the same weights\n",
    "np.random.seed(1)\n",
    "\n",
    "class Net(object):\n",
    "    def __init__(self, n_input=28*28, n_hidden=256, n_output=10):\n",
    "        self.train = True\n",
    "        \n",
    "        self.input_dropout = Dropout(0.01)\n",
    "        self.input_layer = Linear(n_input, n_hidden)\n",
    "        \n",
    "        self.dropout1 = Dropout(0.5)\n",
    "        self.hidden1 = Linear(n_hidden, n_output)\n",
    "\n",
    "        self.relu = ReLU()\n",
    "        self.softmax = Softmax()\n",
    "        self.cross_entropy = CrossEntropy()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.train:\n",
    "            x = self.input_dropout.forward(x)\n",
    "\n",
    "        x = self.input_layer.forward(x)\n",
    "        x = self.relu.forward(x)\n",
    "\n",
    "        if self.train:\n",
    "            x = self.dropout1.forward(x)\n",
    "\n",
    "        x = self.hidden1.forward(x)\n",
    "        x = self.softmax.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def backward(self, targets):\n",
    "        grads = {}\n",
    "        \n",
    "        grad_loss = net.softmax.backward(targets)\n",
    "\n",
    "        grad_hidden_inputs, grad_hidden_weights, grad_hidden_bias = net.hidden1.backward(grad_loss)\n",
    "        grads['w2'] = grad_hidden_weights\n",
    "        grads['b2'] = grad_hidden_bias\n",
    "\n",
    "        grad_relu = net.relu.backward(grad_hidden_inputs)\n",
    "\n",
    "        grad_inputs, grad_input_weights, grad_input_bias = net.input_layer.backward(grad_relu)\n",
    "        grads['w1'] = grad_input_weights\n",
    "        grads['b1'] = grad_input_bias\n",
    "        \n",
    "        return grads\n",
    "    \n",
    "    def loss(self, y_pred, y):\n",
    "        return self.cross_entropy.loss(y_pred, y)\n",
    "\n",
    "net = Net(n_input=28*28, n_hidden=256, n_output=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.3906668132819327 0.3243557661436557 0.9 0.90234375\n",
      "1 0.3260906631377021 0.4547801716592869 0.9125 0.8828125\n",
      "2 0.25048209278271394 0.12696148926633088 0.925 0.9609375\n",
      "3 0.16853272794715904 0.18167559469333397 0.9625 0.9453125\n",
      "4 0.182128664466565 0.2933465308516074 0.95 0.921875\n",
      "5 0.1057985759784315 0.20774606040480825 0.975 0.94921875\n",
      "6 0.1460489863382047 0.10863563436643263 0.9375 0.9609375\n",
      "7 0.19128333736515749 0.2560116427111449 0.925 0.9375\n",
      "8 0.08659846806244902 0.10788185545750609 0.975 0.953125\n",
      "9 0.05223984658798355 0.16733635325407153 0.9875 0.9609375\n"
     ]
    }
   ],
   "source": [
    "debug = False\n",
    "\n",
    "if debug:\n",
    "    n_epochs = 1\n",
    "    batch_size = 3\n",
    "else:\n",
    "    n_epochs = 10\n",
    "    batch_size = 256\n",
    "    \n",
    "learning_rate = 1e-1\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    for i in range(0, len(x_train), batch_size):\n",
    "\n",
    "        inputs = x_train[i:i+batch_size]\n",
    "        targets = y_train[i:i+batch_size]\n",
    "        \n",
    "        inputs, targets = shuffle(inputs, targets)\n",
    "\n",
    "        if debug:\n",
    "            print(\"inputs.shape\", inputs.shape)\n",
    "            print(\"targets.shape\", targets.shape)\n",
    "\n",
    "        # forward propagation\n",
    "        y_pred = net.forward(inputs)\n",
    "        predictions = y_pred.copy()\n",
    "\n",
    "        if debug:\n",
    "            print(\"y_pred.shape:\", y_pred.shape)\n",
    "            print(\"predictions.shape\", predictions.shape)\n",
    "            \n",
    "        # calculate cross-entropy loss\n",
    "        loss = net.loss(predictions, targets)\n",
    "        \n",
    "        if debug:\n",
    "            print(epoch, loss)\n",
    "        \n",
    "        # backpropagation\n",
    "        grads = net.backward(targets)\n",
    "        \n",
    "        if debug:\n",
    "            print(\"w1.shape\", grads['w1'].shape)\n",
    "            print(\"b1.shape\", grads['b1'].shape)\n",
    "            print(\"w2.shape\", grads['w2'].shape)\n",
    "            print(\"b2.shape\", grads['b2'].shape)\n",
    "            \n",
    "        net.input_layer.weights -= learning_rate * grads['w1']\n",
    "        net.input_layer.bias -= learning_rate * grads['b1']\n",
    "        \n",
    "        net.hidden1.weights -= learning_rate * grads['w2']\n",
    "        net.hidden1.bias -= learning_rate * grads['b2']\n",
    "\n",
    "        if debug:\n",
    "            break\n",
    "        \n",
    "    # calculate validation loss for some random indices\n",
    "    net.train = False\n",
    "    random_idxs = np.random.randint(0, len(x_valid), batch_size)\n",
    "    y_valid_pred = net.forward(x_valid[random_idxs])\n",
    "    loss_valid = net.loss(y_valid_pred, y_valid[random_idxs])\n",
    "    net.train = True\n",
    "    \n",
    "    #calculate accuracy and validation accuracy\n",
    "    accuracy = np.mean(y_pred.argmax(axis=1) == targets)\n",
    "    valid_accuracy = np.mean(y_valid_pred.argmax(axis=1) == y_valid[random_idxs])\n",
    "    \n",
    "    print(epoch, loss, loss_valid, accuracy, valid_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3, 4, 2, 3, 0, 0, 3, 5, 6, 4]), array([3, 4, 2, 3, 0, 0, 3, 5, 4, 4]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get some random examples from validation data,\n",
    "# compare predictions with actual values\n",
    "valid_preds = net.forward(x_valid)\n",
    "random_idxs = np.random.randint(0, len(x_valid), 10)\n",
    "np.argmax(valid_preds, axis=1)[random_idxs], y_valid[random_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: 0 correct: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display a random image from validation data with\n",
    "# prediction and correct value\n",
    "valid_images = np.reshape(x_valid, (-1,28,28))\n",
    "valid_preds = net.forward(x_valid)\n",
    "random_idx = np.random.randint(0, len(x_valid))\n",
    "prediction = np.argmax(valid_preds, axis=1)[random_idx]\n",
    "correct = y_valid[random_idx]\n",
    "print(\"prediction:\", prediction, \"correct:\", correct)\n",
    "show(valid_images[random_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9484"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# whole validation set accuracy\n",
    "valid_preds = net.forward(x_valid)\n",
    "valid_accuracy = np.mean(valid_preds.argmax(axis=1) == y_valid)\n",
    "valid_accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
