# Testing

The program is tested with unit tests, integration tests, usage testing and standard Machine Learning testing standards.

## Unit testing

The individual parts of the program (dataloader, layers, losses) are unit tested.

The forward pass is tested by using expected inputs and outputs. The correct inputs and outputs where either generated using PyTorch or found on internet sources like Wikipedia.

    The backward pass is tested using [Gradient Checking](http://ufldl.stanford.edu/wiki/index.php/Gradient_checking_and_advanced_optimization). Code for Gradient Checking was borrowed from [CS231n Assignment 1](http://cs231n.github.io/assignments2016/assignment1/) and then applied for testing the backward pass of the individual layers.

Unit tests are build using the standard python [unittest library](https://docs.python.org/3/library/unittest.html).

Coverage can be generated by running the [coverage](https://coverage.readthedocs.io/en/coverage-4.5.1a/) command.

```
$ coverage run train.py
Epoch Train loss   Valid loss   Train acc Valid acc
0     0.0566909363 0.0831313971 0.9880952 0.9758000
1     0.0808085772 0.0799735359 0.9702381 0.9763000
2     0.0795893411 0.0796035784 0.9761905 0.9764000
3     0.0505969298 0.0790031245 0.9910714 0.9763000
4     0.0455380232 0.0786955328 0.9851190 0.9767000
5     0.0498127134 0.0768455619 0.9821429 0.9781000
6     0.0631084901 0.0778526832 0.9761905 0.9775000
7     0.0483764676 0.0762201181 0.9910714 0.9777000
8     0.0508555297 0.0756136432 0.9851190 0.9786000
9     0.0393794773 0.0737937603 0.9910714 0.9788000
$ coverage report
Name                  Stmts   Miss  Cover
-----------------------------------------
mnist/__init__.py         0      0   100%
mnist/dataloader.py      22      0   100%
mnist/layers.py          70      3    96%
mnist/losses.py           7      0   100%
mnist/models.py          24      0   100%
mnist/networks.py        44      9    80%
mnist/optimizers.py      51      3    94%
train.py                 12      0   100%
-----------------------------------------
TOTAL                   230     15    93%
```

## Integration testing

TBD

## Machine Learning testing

MNIST database comes already divided in three sets. Training set, validation set and test set.

During the training it is very important that only training data is used. The results are then checked against validation set and the weights are adjusted accordingly.

Never during the building of the model or training the model the test set is used.

After the network is ready it is evaluated against the test set data. This provides the accuracy of the neural network model.

The final accuracies are printed out when running _predict.py_ script as follow.

```
$ ./predict.py
Training set accuracy: 0.96574
Validation set accuracy: 0.9603
Test set accuracy: 0.9548
```

